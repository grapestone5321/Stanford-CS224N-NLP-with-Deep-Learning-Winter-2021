# Stanford-CS224N-NLP-with-Deep-Learning-Winter-2021


https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/

https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ

CS224N: Natural Language Processing with Deep Learning | Winter 2021


For more information about Stanfordâ€™s Artificial Intelligence professional and graduate programs, visit: 

https://learn.stanford.edu/Social-AI-YouTube.html?utm_medium=social&utm_term&utm_campaign=AI&utm_source=youtube

stanfordonline

-------

## What is this course about?

Natural language processing (NLP) or computational linguistics is one of the most important technologies of the information age. 

Applications of NLP are everywhere because people communicate almost everything in language: web search, advertising, emails, customer service, language translation, virtual agents, medical reports, etc. 

In recent years, deep learning (or neural network) approaches have obtained very high performance across many different NLP tasks, using single end-to-end neural models that do not require traditional, task-specific feature engineering. 

In this course, students will gain a thorough introduction to cutting-edge research in Deep Learning for NLP. 

Through lectures, assignments and a final project, students will learn the necessary skills to design, implement, and understand their own neural network models.



-------


### 1 1:24:27

Introduction and Word Vectors

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture01-wordvecs1.pdf

### 2 1:15:18

Neural Classifiers

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture02-wordvecs2.pdf

### 3 1:22:29

Backprop and Neural Networks

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture03-neuralnets.pdf

### 4 1:21:22

Dependency Parsing

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture04-dep-parsing.pdf

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture04-dep-parsing-annotated.pdf

### 5 1:19:18

Language Models and RNNs

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture05-rnnlm.pdf

### 6 1:21:38

Simple and LSTM RNNs

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture06-fancy-rnn.pdf

### 7 1:18:55

Translation, Seq2Seq, Attention

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture07-nmt.pdf

### 8 1:20:58

Final Projects; Practical Tips

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture08-final-project.pdf

### 9 1:16:57

Self- Attention and Transformers

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture09-transformers.pdf

### 10 1:21:46

Transformers and Pretraining

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture10-pretraining.pdf

### 11 1:51:53

Question Answering

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture11-qa-v2.pdf

### 12 1:17:27

Natural Language Generation

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture12-generation.pdf

### 13 1:21:46

Coreference Resolution

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture13-coref.pdf

### 14 1:35:14

T5 and Large Language Models

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture14-t5.pdf

### 15 1:17:25

Add Knowledge to Language Models

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture15-lm.pdf

### 16 1:51:15

Social & Ethical Considerations

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture16-ethics.pdf

### 17 1:17:11

Model Analysis and Explanation

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture17-analysis.pdf

### 18 1:20:06

Future of NLP + Deep Learning

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1214/slides/cs224n-2021-lecture18-future.pdf


### 19 1:15:46

Winter 2020

Low Resource Machine Translation

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1204/slides/MarcAurelio_Ranzato_Low_Resource_MT.pdf

### 20 54:29

Winter 2020

BERT and Other Pre-trained Language Models

https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1204/slides/Jacob_Devlin_BERT.pdf

-------
